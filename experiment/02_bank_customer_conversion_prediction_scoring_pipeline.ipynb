{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "M27qF7CTrBqc"
   },
   "source": [
    "# Sklearn Pipeline for Scoring New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data from Local CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nutzer\\AppData\\Local\\Temp\\ipykernel_2660\\1714703530.py:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "      <th>previous_contact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  campaign  pdays  previous     poutcome  y  \\\n",
       "0   may         mon         1    NaN         0  nonexistent  0   \n",
       "1   may         mon         1    NaN         0  nonexistent  0   \n",
       "2   may         mon         1    NaN         0  nonexistent  0   \n",
       "3   may         mon         1    NaN         0  nonexistent  0   \n",
       "4   may         mon         1    NaN         0  nonexistent  0   \n",
       "\n",
       "  previous_contact  \n",
       "0               no  \n",
       "1               no  \n",
       "2               no  \n",
       "3               no  \n",
       "4               no  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data from local csv \n",
    "df = pd.read_csv(\n",
    "        filepath_or_buffer = '../data/bank-additional-full.csv',\n",
    "        sep=';'\n",
    ")\n",
    "\n",
    "# drop a few columns which are typically not available in many scenarios or columns which leads to leakage b/c it cannot be known beforehand!\n",
    "df.drop(\n",
    "        labels=['duration', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx','euribor3m', 'nr.employed'], \n",
    "        axis=1, \n",
    "        inplace=True)\n",
    "\n",
    "# make feature denoting if there was a previous contact\n",
    "df['previous_contact'] = (df['pdays'] != 999).apply(lambda x: 'no' if x==False else 'yes')\n",
    "\n",
    "# insert random value if value equal 999 since the values is not defined\n",
    "df['pdays'] = df['pdays'].apply(lambda x: np.nan if x==999 else x)\n",
    "\n",
    "# encode target column\n",
    "df['y'] = df['y'].apply(lambda x: 0 if x=='no' else 1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_my_postgre_db(password:str, table_name:str)->pd.DataFrame:\n",
    "    \"\"\"connects to marketing_analytics db and returns data from table_name as pandas dataframe .\n",
    "    inputs: database password and table_name\"\"\"\n",
    "    # Connect to the database\n",
    "    conn = psycopg2.connect(\n",
    "        database=\"marketing_analytics\", \n",
    "        user=\"postgres\", \n",
    "        password=password, \n",
    "        host=\"localhost\", \n",
    "        port=\"5432\")\n",
    "    # Create a cursor object\n",
    "    cur = conn.cursor()\n",
    "    # Execute a SQL query\n",
    "    #cur.execute(\"SELECT * FROM bank_customers_churn_dataset\")\n",
    "    cur.execute(\"SELECT * FROM \" + table_name) \n",
    "    # Get the column names from the cursor description\n",
    "    columns = [desc[0] for desc in cur.description]\n",
    "    # Fetch the results i.e. values\n",
    "    results = cur.fetchall()\n",
    "    # Create a dictionary mapping column names to values\n",
    "    data = [dict(zip(columns, row)) for row in results]\n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "    # turn dictionary into dataframe\n",
    "    return pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data from Postgres Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = open(\"../private.txt\", \"r\")\n",
    "#pw = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get data from postres db\n",
    "#table_name = \"bank_customers_churn_dataset\"\n",
    "#df = get_data_from_my_postgre_db(pw, table_name)\n",
    "#\n",
    "## set customer id as index\n",
    "#df.set_index('customer_id', inplace=True)\n",
    "#\n",
    "## change churn column type to bool\n",
    "#df['churn'] = df['churn'].astype('int').astype('bool')\n",
    "#\n",
    "## change data types to numeric\n",
    "#df['tenure'] = df['tenure'].apply(lambda x: int(x))\n",
    "#df['products_number'] = df['products_number'].apply(lambda x: int(x))\n",
    "#df['credit_card'] = df['credit_card'].apply(lambda x: int(x))\n",
    "#df['active_member'] = df['active_member'].apply(lambda x: int(x))\n",
    "#\n",
    "## change type of categorical columns \"credit_card\" and \"active_member\"\n",
    "#df['credit_card'] = df['credit_card'].apply(lambda x: 'yes' if x == 1 else 'no')\n",
    "#df['active_member'] = df['active_member'].apply(lambda x: 'yes' if x == 1 else 'no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get features and throw away target if there is any already; there is no target!\n",
    "#df = df.iloc[:,:-1]\n",
    "#df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../artifacts/numeric_imputer.pickle', 'rb') as filename: # trained model to impute missing numeric data\n",
    "    numeric_imputer = pickle.load(filename)\n",
    "\n",
    "with open('../artifacts/categorical_imputer.pickle', 'rb') as filename: # trained model to impute missing categorical data\n",
    "    categorical_imputer = pickle.load(filename) \n",
    "\n",
    "with open('../artifacts/rare_encoder.pickle', 'rb') as filename: # trained model to encode rare labels\n",
    "    rare_encoder = pickle.load(filename)\n",
    "\n",
    "with open('../artifacts/capper.pickle', 'rb') as filename: # trained model to cap outliers\n",
    "    capper = pickle.load(filename)   \n",
    "\n",
    "with open('../artifacts/enc.pickle', 'rb') as filename: # trained one hot encoder\n",
    "    enc = pickle.load(filename)\n",
    "\n",
    "with open('../artifacts/model.pickle', 'rb') as filename: # trained random forrest classifier\n",
    "    model = pickle.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('y', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numeric columns: ['age', 'campaign', 'pdays', 'previous']\n",
      "categorical columns: ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome', 'previous_contact']\n"
     ]
    }
   ],
   "source": [
    "# get numeric and categorical columns\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numeric_columns = X.select_dtypes(include=numerics).columns.to_list()\n",
    "categorical_columns = X.select_dtypes(exclude=numerics).columns.to_list()\n",
    "\n",
    "print('numeric columns: {}'.format(numeric_columns))\n",
    "print('categorical columns: {}'.format(categorical_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>job_admin.</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_management</th>\n",
       "      <th>job_services</th>\n",
       "      <th>job_technician</th>\n",
       "      <th>marital_married</th>\n",
       "      <th>...</th>\n",
       "      <th>month_jun</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>day_of_week_mon</th>\n",
       "      <th>day_of_week_thu</th>\n",
       "      <th>day_of_week_tue</th>\n",
       "      <th>day_of_week_wed</th>\n",
       "      <th>poutcome_nonexistent</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>previous_contact_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.656443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.656443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.656443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.656443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.656443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  campaign      pdays  previous  job_admin.  job_blue-collar  \\\n",
       "0  56.0       1.0  17.656443       0.0         0.0              0.0   \n",
       "1  57.0       1.0  17.656443       0.0         0.0              0.0   \n",
       "2  37.0       1.0  17.656443       0.0         0.0              0.0   \n",
       "3  40.0       1.0  17.656443       0.0         1.0              0.0   \n",
       "4  56.0       1.0  17.656443       0.0         0.0              0.0   \n",
       "\n",
       "   job_management  job_services  job_technician  marital_married  ...  \\\n",
       "0             0.0           0.0             0.0              1.0  ...   \n",
       "1             0.0           1.0             0.0              1.0  ...   \n",
       "2             0.0           1.0             0.0              1.0  ...   \n",
       "3             0.0           0.0             0.0              1.0  ...   \n",
       "4             0.0           1.0             0.0              1.0  ...   \n",
       "\n",
       "   month_jun  month_may  month_nov  day_of_week_mon  day_of_week_thu  \\\n",
       "0        0.0        1.0        0.0              1.0              0.0   \n",
       "1        0.0        1.0        0.0              1.0              0.0   \n",
       "2        0.0        1.0        0.0              1.0              0.0   \n",
       "3        0.0        1.0        0.0              1.0              0.0   \n",
       "4        0.0        1.0        0.0              1.0              0.0   \n",
       "\n",
       "   day_of_week_tue  day_of_week_wed  poutcome_nonexistent  poutcome_success  \\\n",
       "0              0.0              0.0                   1.0               0.0   \n",
       "1              0.0              0.0                   1.0               0.0   \n",
       "2              0.0              0.0                   1.0               0.0   \n",
       "3              0.0              0.0                   1.0               0.0   \n",
       "4              0.0              0.0                   1.0               0.0   \n",
       "\n",
       "   previous_contact_yes  \n",
       "0                   0.0  \n",
       "1                   0.0  \n",
       "2                   0.0  \n",
       "3                   0.0  \n",
       "4                   0.0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# impute mising numeric features\n",
    "df_numeric = pd.DataFrame(\n",
    "    numeric_imputer.transform(df[numeric_columns]), \n",
    "    columns=numeric_columns, \n",
    "    index=df.index)\n",
    "\n",
    "# impute mising categorical features\n",
    "df_categorical = pd.DataFrame(\n",
    "    categorical_imputer.transform(df[categorical_columns]), \n",
    "    columns=categorical_columns, \n",
    "    index=df.index)\n",
    "\n",
    "# concate numeric and categorical features\n",
    "df = pd.concat([df_numeric, df_categorical], axis=1)\n",
    "\n",
    "# remove rare labels\n",
    "df[categorical_columns] = rare_encoder.transform(df[categorical_columns])\n",
    "\n",
    "# remove outliers\n",
    "df[numeric_columns] = capper.transform(df[numeric_columns])\n",
    "\n",
    "# one hot encoding categorical features\n",
    "df_cat_hotenc = pd.DataFrame(\n",
    "    enc.transform(df[categorical_columns]), \n",
    "    columns=enc.get_feature_names_out(),\n",
    "    index=df.index) \n",
    "\n",
    "# concate numeric and hot-encoded categorical features\n",
    "df_hotenc = pd.concat([df[numeric_columns], df_cat_hotenc], axis=1)\n",
    "\n",
    "df_hotenc.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nutzer\\.conda\\envs\\customer_analytics\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- default_yes\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 38 features, but GradientBoostingClassifier is expecting 37 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32me:\\GoogleDrive\\Beruf\\Freelancing\\Code_Repo\\Customer_Analytics\\Marketing-Sales-Conversion-Prediction-Webapp\\experiment\\02_bank_customer_conversion_prediction_scoring_pipeline.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/GoogleDrive/Beruf/Freelancing/Code_Repo/Customer_Analytics/Marketing-Sales-Conversion-Prediction-Webapp/experiment/02_bank_customer_conversion_prediction_scoring_pipeline.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# predict churn probabilities\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/GoogleDrive/Beruf/Freelancing/Code_Repo/Customer_Analytics/Marketing-Sales-Conversion-Prediction-Webapp/experiment/02_bank_customer_conversion_prediction_scoring_pipeline.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mconversion_probab\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict_proba(df_hotenc)[:,\u001b[39m1\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/GoogleDrive/Beruf/Freelancing/Code_Repo/Customer_Analytics/Marketing-Sales-Conversion-Prediction-Webapp/experiment/02_bank_customer_conversion_prediction_scoring_pipeline.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# predict churn using churn threshold > 0.5\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/GoogleDrive/Beruf/Freelancing/Code_Repo/Customer_Analytics/Marketing-Sales-Conversion-Prediction-Webapp/experiment/02_bank_customer_conversion_prediction_scoring_pipeline.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m threshold \u001b[39m=\u001b[39m \u001b[39m0.3\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Nutzer\\.conda\\envs\\customer_analytics\\lib\\site-packages\\sklearn\\model_selection\\_search.py:523\u001b[0m, in \u001b[0;36mBaseSearchCV.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[39m\"\"\"Call predict_proba on the estimator with the best found parameters.\u001b[39;00m\n\u001b[0;32m    505\u001b[0m \n\u001b[0;32m    506\u001b[0m \u001b[39mOnly available if ``refit=True`` and the underlying estimator supports\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[39m    to that in the fitted attribute :term:`classes_`.\u001b[39;00m\n\u001b[0;32m    521\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    522\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 523\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbest_estimator_\u001b[39m.\u001b[39;49mpredict_proba(X)\n",
      "File \u001b[1;32mc:\\Users\\Nutzer\\.conda\\envs\\customer_analytics\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:1496\u001b[0m, in \u001b[0;36mGradientBoostingClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1475\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_proba\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m   1476\u001b[0m     \u001b[39m\"\"\"Predict class probabilities for X.\u001b[39;00m\n\u001b[0;32m   1477\u001b[0m \n\u001b[0;32m   1478\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1494\u001b[0m \u001b[39m        If the ``loss`` does not support probabilities.\u001b[39;00m\n\u001b[0;32m   1495\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1496\u001b[0m     raw_predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecision_function(X)\n\u001b[0;32m   1497\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1498\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_loss\u001b[39m.\u001b[39m_raw_prediction_to_proba(raw_predictions)\n",
      "File \u001b[1;32mc:\\Users\\Nutzer\\.conda\\envs\\customer_analytics\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:1402\u001b[0m, in \u001b[0;36mGradientBoostingClassifier.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1383\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecision_function\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m   1384\u001b[0m     \u001b[39m\"\"\"Compute the decision function of ``X``.\u001b[39;00m\n\u001b[0;32m   1385\u001b[0m \n\u001b[0;32m   1386\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1400\u001b[0m \u001b[39m        array of shape (n_samples,).\u001b[39;00m\n\u001b[0;32m   1401\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1402\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m   1403\u001b[0m         X, dtype\u001b[39m=\u001b[39;49mDTYPE, order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[0;32m   1404\u001b[0m     )\n\u001b[0;32m   1405\u001b[0m     raw_predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raw_predict(X)\n\u001b[0;32m   1406\u001b[0m     \u001b[39mif\u001b[39;00m raw_predictions\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Nutzer\\.conda\\envs\\customer_analytics\\lib\\site-packages\\sklearn\\base.py:600\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> 600\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m    602\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\Nutzer\\.conda\\envs\\customer_analytics\\lib\\site-packages\\sklearn\\base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 400\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    401\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    402\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    403\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 38 features, but GradientBoostingClassifier is expecting 37 features as input."
     ]
    }
   ],
   "source": [
    "# predict churn probabilities\n",
    "df['conversion_probab'] = model.predict_proba(df_hotenc)[:,1]\n",
    "\n",
    "# predict churn using churn threshold > 0.5\n",
    "threshold = 0.3\n",
    "df['conversion_predicted'] = np.where(df['conversion_probab'].values > threshold, 1, 0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    37668\n",
       "1     3520\n",
       "Name: conversion_predicted, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cluster Counts\n",
    "df['conversion_predicted'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nutzer\\AppData\\Local\\Temp\\ipykernel_2752\\3975600335.py:4: FutureWarning: ['conversion_probab'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
      "  df.groupby(by='conversion_predicted').aggregate(pd.Series.mode)[categorical_columns] ],\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>conversion_probab</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>previous_contact</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversion_predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.882255</td>\n",
       "      <td>2.553375</td>\n",
       "      <td>17.510357</td>\n",
       "      <td>0.115702</td>\n",
       "      <td>0.068780</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.314622</td>\n",
       "      <td>1.762903</td>\n",
       "      <td>13.343603</td>\n",
       "      <td>0.663784</td>\n",
       "      <td>0.558952</td>\n",
       "      <td>Rare</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>Rare</td>\n",
       "      <td>thu</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            age  campaign      pdays  previous  \\\n",
       "conversion_predicted                                             \n",
       "0                     39.882255  2.553375  17.510357  0.115702   \n",
       "1                     41.314622  1.762903  13.343603  0.663784   \n",
       "\n",
       "                      conversion_probab     job  marital          education  \\\n",
       "conversion_predicted                                                          \n",
       "0                              0.068780  admin.  married  university.degree   \n",
       "1                              0.558952    Rare  married  university.degree   \n",
       "\n",
       "                     default housing loan   contact month day_of_week  \\\n",
       "conversion_predicted                                                    \n",
       "0                         no     yes   no  cellular   may         mon   \n",
       "1                         no     yes   no  cellular  Rare         thu   \n",
       "\n",
       "                         poutcome previous_contact  \n",
       "conversion_predicted                                \n",
       "0                     nonexistent               no  \n",
       "1                     nonexistent               no  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cluster Centers\n",
    "pd.concat([\n",
    "    df.groupby(by='conversion_predicted').mean(),\n",
    "    df.groupby(by='conversion_predicted').aggregate(pd.Series.mode)[categorical_columns] ],\n",
    "    axis=1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "customer_analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 06:59:08) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "d6d257a4de92dbbd8540bc21a788c880e0ed004671baa4a130c0cbca69d8aa15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
